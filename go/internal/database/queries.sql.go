// Code generated by sqlc. DO NOT EDIT.
// versions:
//   sqlc v1.30.0
// source: queries.sql

package database

import (
	"context"
	"database/sql"
	"time"
)

const cleanupStaleJobs = `-- name: CleanupStaleJobs :exec
UPDATE jobs
SET worker_id = NULL, status = 'pending', expires_at = NULL
WHERE status = 'processing'
    AND last_checkpoint_at < datetime('now', 'utc', '-' || ?1 || ' seconds')
`

// Clear worker assignment for long-stale processing jobs so they can be re-leased
func (q *Queries) CleanupStaleJobs(ctx context.Context, thresholdSeconds sql.NullString) error {
	_, err := q.db.ExecContext(ctx, cleanupStaleJobs, thresholdSeconds)
	return err
}

const completeBatch = `-- name: CompleteBatch :exec
UPDATE jobs
SET 
    status = 'completed',
    completed_at = datetime('now', 'utc'),
    keys_scanned = ?,
    duration_ms = ?,
    current_nonce = nonce_end
WHERE id = ? AND worker_id = ?
`

type CompleteBatchParams struct {
	KeysScanned sql.NullInt64  `json:"keys_scanned"`
	DurationMs  sql.NullInt64  `json:"duration_ms"`
	ID          int64          `json:"id"`
	WorkerID    sql.NullString `json:"worker_id"`
}

// Mark a batch as completed
func (q *Queries) CompleteBatch(ctx context.Context, arg CompleteBatchParams) error {
	_, err := q.db.ExecContext(ctx, completeBatch,
		arg.KeysScanned,
		arg.DurationMs,
		arg.ID,
		arg.WorkerID,
	)
	return err
}

const createBatch = `-- name: CreateBatch :one
INSERT INTO jobs (
    prefix_28, 
    nonce_start, 
    nonce_end,
    current_nonce,
    status, 
    worker_id,
    worker_type,
    expires_at,
    requested_batch_size
)
VALUES (?, ?, ?, ?, 'processing', ?, ?, datetime('now', 'utc', '+' || ? || ' seconds'), ?)
RETURNING id, prefix_28, nonce_start, nonce_end, current_nonce, status, worker_id, worker_type, expires_at, created_at, completed_at, keys_scanned, requested_batch_size, last_checkpoint_at, duration_ms
`

type CreateBatchParams struct {
	Prefix28           []byte         `json:"prefix_28"`
	NonceStart         int64          `json:"nonce_start"`
	NonceEnd           int64          `json:"nonce_end"`
	CurrentNonce       sql.NullInt64  `json:"current_nonce"`
	WorkerID           sql.NullString `json:"worker_id"`
	WorkerType         sql.NullString `json:"worker_type"`
	LeaseSeconds       sql.NullString `json:"lease_seconds"`
	RequestedBatchSize sql.NullInt64  `json:"requested_batch_size"`
}

// Create a new batch (job) for a worker
func (q *Queries) CreateBatch(ctx context.Context, arg CreateBatchParams) (Job, error) {
	row := q.db.QueryRowContext(ctx, createBatch,
		arg.Prefix28,
		arg.NonceStart,
		arg.NonceEnd,
		arg.CurrentNonce,
		arg.WorkerID,
		arg.WorkerType,
		arg.LeaseSeconds,
		arg.RequestedBatchSize,
	)
	var i Job
	err := row.Scan(
		&i.ID,
		&i.Prefix28,
		&i.NonceStart,
		&i.NonceEnd,
		&i.CurrentNonce,
		&i.Status,
		&i.WorkerID,
		&i.WorkerType,
		&i.ExpiresAt,
		&i.CreatedAt,
		&i.CompletedAt,
		&i.KeysScanned,
		&i.RequestedBatchSize,
		&i.LastCheckpointAt,
		&i.DurationMs,
	)
	return i, err
}

const createMacroJob = `-- name: CreateMacroJob :one
INSERT INTO jobs (
        prefix_28,
        nonce_start,
        nonce_end,
        current_nonce,
        status,
        worker_id,
        worker_type,
        expires_at,
        requested_batch_size
)
VALUES (?, ?, ?, ?, 'processing', ?, ?, datetime('now', 'utc', '+' || ? || ' seconds'), ?)
RETURNING id, prefix_28, nonce_start, nonce_end, current_nonce, status, worker_id, worker_type, expires_at, created_at, completed_at, keys_scanned, requested_batch_size, last_checkpoint_at, duration_ms
`

type CreateMacroJobParams struct {
	Prefix28           []byte         `json:"prefix_28"`
	NonceStart         int64          `json:"nonce_start"`
	NonceEnd           int64          `json:"nonce_end"`
	CurrentNonce       sql.NullInt64  `json:"current_nonce"`
	WorkerID           sql.NullString `json:"worker_id"`
	WorkerType         sql.NullString `json:"worker_type"`
	LeaseSeconds       sql.NullString `json:"lease_seconds"`
	RequestedBatchSize sql.NullInt64  `json:"requested_batch_size"`
}

// Create a long-lived macro job covering the full nonce space for a prefix
func (q *Queries) CreateMacroJob(ctx context.Context, arg CreateMacroJobParams) (Job, error) {
	row := q.db.QueryRowContext(ctx, createMacroJob,
		arg.Prefix28,
		arg.NonceStart,
		arg.NonceEnd,
		arg.CurrentNonce,
		arg.WorkerID,
		arg.WorkerType,
		arg.LeaseSeconds,
		arg.RequestedBatchSize,
	)
	var i Job
	err := row.Scan(
		&i.ID,
		&i.Prefix28,
		&i.NonceStart,
		&i.NonceEnd,
		&i.CurrentNonce,
		&i.Status,
		&i.WorkerID,
		&i.WorkerType,
		&i.ExpiresAt,
		&i.CreatedAt,
		&i.CompletedAt,
		&i.KeysScanned,
		&i.RequestedBatchSize,
		&i.LastCheckpointAt,
		&i.DurationMs,
	)
	return i, err
}

const findAvailableBatch = `-- name: FindAvailableBatch :one
SELECT id, prefix_28, nonce_start, nonce_end, current_nonce, status, worker_id, worker_type, expires_at, created_at, completed_at, keys_scanned, requested_batch_size, last_checkpoint_at, duration_ms FROM jobs
WHERE status = 'pending' 
   OR (status = 'processing' AND expires_at < datetime('now', 'utc'))
ORDER BY created_at ASC
LIMIT 1
`

// Find an available batch (pending or expired lease)
func (q *Queries) FindAvailableBatch(ctx context.Context) (Job, error) {
	row := q.db.QueryRowContext(ctx, findAvailableBatch)
	var i Job
	err := row.Scan(
		&i.ID,
		&i.Prefix28,
		&i.NonceStart,
		&i.NonceEnd,
		&i.CurrentNonce,
		&i.Status,
		&i.WorkerID,
		&i.WorkerType,
		&i.ExpiresAt,
		&i.CreatedAt,
		&i.CompletedAt,
		&i.KeysScanned,
		&i.RequestedBatchSize,
		&i.LastCheckpointAt,
		&i.DurationMs,
	)
	return i, err
}

const findIncompleteMacroJob = `-- name: FindIncompleteMacroJob :one
SELECT id, prefix_28, nonce_start, nonce_end, current_nonce, status, worker_id, worker_type, expires_at, created_at, completed_at, keys_scanned, requested_batch_size, last_checkpoint_at, duration_ms FROM jobs
WHERE prefix_28 = ?
    AND status != 'completed'
ORDER BY created_at ASC
LIMIT 1
`

// Find an existing non-completed (macro) job for a given prefix
func (q *Queries) FindIncompleteMacroJob(ctx context.Context, prefix28 []byte) (Job, error) {
	row := q.db.QueryRowContext(ctx, findIncompleteMacroJob, prefix28)
	var i Job
	err := row.Scan(
		&i.ID,
		&i.Prefix28,
		&i.NonceStart,
		&i.NonceEnd,
		&i.CurrentNonce,
		&i.Status,
		&i.WorkerID,
		&i.WorkerType,
		&i.ExpiresAt,
		&i.CreatedAt,
		&i.CompletedAt,
		&i.KeysScanned,
		&i.RequestedBatchSize,
		&i.LastCheckpointAt,
		&i.DurationMs,
	)
	return i, err
}

const getActiveWorkers = `-- name: GetActiveWorkers :many
SELECT id, worker_type, last_seen, total_keys_scanned, metadata, created_at, updated_at FROM workers
WHERE last_seen > datetime('now', '-' || ? || ' minutes')
ORDER BY last_seen DESC
`

// Get workers active in the last N minutes
func (q *Queries) GetActiveWorkers(ctx context.Context, dollar_1 sql.NullString) ([]Worker, error) {
	rows, err := q.db.QueryContext(ctx, getActiveWorkers, dollar_1)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	items := []Worker{}
	for rows.Next() {
		var i Worker
		if err := rows.Scan(
			&i.ID,
			&i.WorkerType,
			&i.LastSeen,
			&i.TotalKeysScanned,
			&i.Metadata,
			&i.CreatedAt,
			&i.UpdatedAt,
		); err != nil {
			return nil, err
		}
		items = append(items, i)
	}
	if err := rows.Close(); err != nil {
		return nil, err
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const getAllResults = `-- name: GetAllResults :many
SELECT id, private_key, address, worker_id, job_id, nonce_found, found_at FROM results
ORDER BY found_at DESC
LIMIT ?
`

// Get all results (limited)
func (q *Queries) GetAllResults(ctx context.Context, limit int64) ([]Result, error) {
	rows, err := q.db.QueryContext(ctx, getAllResults, limit)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	items := []Result{}
	for rows.Next() {
		var i Result
		if err := rows.Scan(
			&i.ID,
			&i.PrivateKey,
			&i.Address,
			&i.WorkerID,
			&i.JobID,
			&i.NonceFound,
			&i.FoundAt,
		); err != nil {
			return nil, err
		}
		items = append(items, i)
	}
	if err := rows.Close(); err != nil {
		return nil, err
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const getAllWorkerLifetimeStats = `-- name: GetAllWorkerLifetimeStats :many
SELECT worker_id, worker_type, total_batches, total_keys_scanned, total_duration_ms, keys_per_second_avg, keys_per_second_best, keys_per_second_worst, first_seen_at, last_seen_at FROM worker_stats_lifetime
ORDER BY total_keys_scanned DESC
`

func (q *Queries) GetAllWorkerLifetimeStats(ctx context.Context) ([]WorkerStatsLifetime, error) {
	rows, err := q.db.QueryContext(ctx, getAllWorkerLifetimeStats)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	items := []WorkerStatsLifetime{}
	for rows.Next() {
		var i WorkerStatsLifetime
		if err := rows.Scan(
			&i.WorkerID,
			&i.WorkerType,
			&i.TotalBatches,
			&i.TotalKeysScanned,
			&i.TotalDurationMs,
			&i.KeysPerSecondAvg,
			&i.KeysPerSecondBest,
			&i.KeysPerSecondWorst,
			&i.FirstSeenAt,
			&i.LastSeenAt,
		); err != nil {
			return nil, err
		}
		items = append(items, i)
	}
	if err := rows.Close(); err != nil {
		return nil, err
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const getJobByID = `-- name: GetJobByID :one
SELECT id, prefix_28, nonce_start, nonce_end, current_nonce, status, worker_id, worker_type, expires_at, created_at, completed_at, keys_scanned, requested_batch_size, last_checkpoint_at, duration_ms FROM jobs
WHERE id = ?
`

// Get a specific job by ID
func (q *Queries) GetJobByID(ctx context.Context, id int64) (Job, error) {
	row := q.db.QueryRowContext(ctx, getJobByID, id)
	var i Job
	err := row.Scan(
		&i.ID,
		&i.Prefix28,
		&i.NonceStart,
		&i.NonceEnd,
		&i.CurrentNonce,
		&i.Status,
		&i.WorkerID,
		&i.WorkerType,
		&i.ExpiresAt,
		&i.CreatedAt,
		&i.CompletedAt,
		&i.KeysScanned,
		&i.RequestedBatchSize,
		&i.LastCheckpointAt,
		&i.DurationMs,
	)
	return i, err
}

const getJobsByStatus = `-- name: GetJobsByStatus :many
SELECT id, prefix_28, nonce_start, nonce_end, current_nonce, status, worker_id, worker_type, expires_at, created_at, completed_at, keys_scanned, requested_batch_size, last_checkpoint_at, duration_ms FROM jobs
WHERE status = ?
ORDER BY created_at DESC
LIMIT ?
`

type GetJobsByStatusParams struct {
	Status string `json:"status"`
	Limit  int64  `json:"limit"`
}

// Get jobs by status
func (q *Queries) GetJobsByStatus(ctx context.Context, arg GetJobsByStatusParams) ([]Job, error) {
	rows, err := q.db.QueryContext(ctx, getJobsByStatus, arg.Status, arg.Limit)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	items := []Job{}
	for rows.Next() {
		var i Job
		if err := rows.Scan(
			&i.ID,
			&i.Prefix28,
			&i.NonceStart,
			&i.NonceEnd,
			&i.CurrentNonce,
			&i.Status,
			&i.WorkerID,
			&i.WorkerType,
			&i.ExpiresAt,
			&i.CreatedAt,
			&i.CompletedAt,
			&i.KeysScanned,
			&i.RequestedBatchSize,
			&i.LastCheckpointAt,
			&i.DurationMs,
		); err != nil {
			return nil, err
		}
		items = append(items, i)
	}
	if err := rows.Close(); err != nil {
		return nil, err
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const getJobsByWorker = `-- name: GetJobsByWorker :many
SELECT id, prefix_28, nonce_start, nonce_end, current_nonce, status, worker_id, worker_type, expires_at, created_at, completed_at, keys_scanned, requested_batch_size, last_checkpoint_at, duration_ms FROM jobs
WHERE worker_id = ?
ORDER BY created_at DESC
`

// Get all jobs assigned to a specific worker
func (q *Queries) GetJobsByWorker(ctx context.Context, workerID sql.NullString) ([]Job, error) {
	rows, err := q.db.QueryContext(ctx, getJobsByWorker, workerID)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	items := []Job{}
	for rows.Next() {
		var i Job
		if err := rows.Scan(
			&i.ID,
			&i.Prefix28,
			&i.NonceStart,
			&i.NonceEnd,
			&i.CurrentNonce,
			&i.Status,
			&i.WorkerID,
			&i.WorkerType,
			&i.ExpiresAt,
			&i.CreatedAt,
			&i.CompletedAt,
			&i.KeysScanned,
			&i.RequestedBatchSize,
			&i.LastCheckpointAt,
			&i.DurationMs,
		); err != nil {
			return nil, err
		}
		items = append(items, i)
	}
	if err := rows.Close(); err != nil {
		return nil, err
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const getNextNonceRange = `-- name: GetNextNonceRange :one
SELECT MAX(nonce_end) as last_nonce_end
FROM jobs
WHERE prefix_28 = ?
AND status IN ('processing', 'completed')
`

// Get the next available nonce range for a specific prefix
func (q *Queries) GetNextNonceRange(ctx context.Context, prefix28 []byte) (interface{}, error) {
	row := q.db.QueryRowContext(ctx, getNextNonceRange, prefix28)
	var last_nonce_end interface{}
	err := row.Scan(&last_nonce_end)
	return last_nonce_end, err
}

const getPrefixUsage = `-- name: GetPrefixUsage :many
SELECT 
    prefix_28,
    COUNT(*) as total_batches,
    SUM(CASE WHEN status = 'completed' THEN 1 ELSE 0 END) as completed_batches,
    MAX(nonce_end) as highest_nonce,
    SUM(keys_scanned) as total_keys_scanned
FROM jobs
GROUP BY prefix_28
ORDER BY prefix_28
LIMIT ?
`

type GetPrefixUsageRow struct {
	Prefix28         []byte          `json:"prefix_28"`
	TotalBatches     int64           `json:"total_batches"`
	CompletedBatches sql.NullFloat64 `json:"completed_batches"`
	HighestNonce     interface{}     `json:"highest_nonce"`
	TotalKeysScanned sql.NullFloat64 `json:"total_keys_scanned"`
}

// Get usage statistics per prefix
func (q *Queries) GetPrefixUsage(ctx context.Context, limit int64) ([]GetPrefixUsageRow, error) {
	rows, err := q.db.QueryContext(ctx, getPrefixUsage, limit)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	items := []GetPrefixUsageRow{}
	for rows.Next() {
		var i GetPrefixUsageRow
		if err := rows.Scan(
			&i.Prefix28,
			&i.TotalBatches,
			&i.CompletedBatches,
			&i.HighestNonce,
			&i.TotalKeysScanned,
		); err != nil {
			return nil, err
		}
		items = append(items, i)
	}
	if err := rows.Close(); err != nil {
		return nil, err
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const getRecentWorkerHistory = `-- name: GetRecentWorkerHistory :many
SELECT id, worker_id, worker_type, job_id, batch_size, keys_scanned, duration_ms, keys_per_second, prefix_28, nonce_start, nonce_end, finished_at, error_message FROM worker_history
WHERE finished_at > datetime('now', '-' || ? || ' seconds')
ORDER BY finished_at DESC
LIMIT ?
`

type GetRecentWorkerHistoryParams struct {
	Column1 sql.NullString `json:"column_1"`
	Limit   int64          `json:"limit"`
}

func (q *Queries) GetRecentWorkerHistory(ctx context.Context, arg GetRecentWorkerHistoryParams) ([]WorkerHistory, error) {
	rows, err := q.db.QueryContext(ctx, getRecentWorkerHistory, arg.Column1, arg.Limit)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	items := []WorkerHistory{}
	for rows.Next() {
		var i WorkerHistory
		if err := rows.Scan(
			&i.ID,
			&i.WorkerID,
			&i.WorkerType,
			&i.JobID,
			&i.BatchSize,
			&i.KeysScanned,
			&i.DurationMs,
			&i.KeysPerSecond,
			&i.Prefix28,
			&i.NonceStart,
			&i.NonceEnd,
			&i.FinishedAt,
			&i.ErrorMessage,
		); err != nil {
			return nil, err
		}
		items = append(items, i)
	}
	if err := rows.Close(); err != nil {
		return nil, err
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const getResultByPrivateKey = `-- name: GetResultByPrivateKey :one
SELECT id, private_key, address, worker_id, job_id, nonce_found, found_at FROM results
WHERE private_key = ?
`

// Find a result by private key
func (q *Queries) GetResultByPrivateKey(ctx context.Context, privateKey string) (Result, error) {
	row := q.db.QueryRowContext(ctx, getResultByPrivateKey, privateKey)
	var i Result
	err := row.Scan(
		&i.ID,
		&i.PrivateKey,
		&i.Address,
		&i.WorkerID,
		&i.JobID,
		&i.NonceFound,
		&i.FoundAt,
	)
	return i, err
}

const getResultsByAddress = `-- name: GetResultsByAddress :many
SELECT id, private_key, address, worker_id, job_id, nonce_found, found_at FROM results
WHERE address = ?
ORDER BY found_at DESC
`

// Find results by Ethereum address
func (q *Queries) GetResultsByAddress(ctx context.Context, address string) ([]Result, error) {
	rows, err := q.db.QueryContext(ctx, getResultsByAddress, address)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	items := []Result{}
	for rows.Next() {
		var i Result
		if err := rows.Scan(
			&i.ID,
			&i.PrivateKey,
			&i.Address,
			&i.WorkerID,
			&i.JobID,
			&i.NonceFound,
			&i.FoundAt,
		); err != nil {
			return nil, err
		}
		items = append(items, i)
	}
	if err := rows.Close(); err != nil {
		return nil, err
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const getStats = `-- name: GetStats :one
SELECT pending_batches, processing_batches, completed_batches, total_batches, total_keys_scanned, avg_pc_batch_size, avg_esp32_batch_size, results_found, total_workers, active_workers, pc_workers, esp32_workers, active_prefixes FROM stats_summary
`

// Get aggregated statistics
func (q *Queries) GetStats(ctx context.Context) (StatsSummary, error) {
	row := q.db.QueryRowContext(ctx, getStats)
	var i StatsSummary
	err := row.Scan(
		&i.PendingBatches,
		&i.ProcessingBatches,
		&i.CompletedBatches,
		&i.TotalBatches,
		&i.TotalKeysScanned,
		&i.AvgPcBatchSize,
		&i.AvgEsp32BatchSize,
		&i.ResultsFound,
		&i.TotalWorkers,
		&i.ActiveWorkers,
		&i.PcWorkers,
		&i.Esp32Workers,
		&i.ActivePrefixes,
	)
	return i, err
}

const getWorkerByID = `-- name: GetWorkerByID :one
SELECT id, worker_type, last_seen, total_keys_scanned, metadata, created_at, updated_at FROM workers
WHERE id = ?
`

// Get worker information by ID
func (q *Queries) GetWorkerByID(ctx context.Context, id string) (Worker, error) {
	row := q.db.QueryRowContext(ctx, getWorkerByID, id)
	var i Worker
	err := row.Scan(
		&i.ID,
		&i.WorkerType,
		&i.LastSeen,
		&i.TotalKeysScanned,
		&i.Metadata,
		&i.CreatedAt,
		&i.UpdatedAt,
	)
	return i, err
}

const getWorkerDailyStats = `-- name: GetWorkerDailyStats :many
SELECT id, worker_id, stats_date, total_batches, total_keys_scanned, total_duration_ms, keys_per_second_avg, keys_per_second_min, keys_per_second_max, error_count FROM worker_stats_daily
WHERE worker_id = ? AND stats_date >= substr(?, 1, 10)
ORDER BY stats_date DESC
`

type GetWorkerDailyStatsParams struct {
	WorkerID string      `json:"worker_id"`
	SUBSTR   interface{} `json:"SUBSTR"`
}

// Accept a full timestamp/time.Time parameter but compare only the date portion (YYYY-MM-DD)
// This makes the generated sqlc method usable directly with a Go time.Time value.
func (q *Queries) GetWorkerDailyStats(ctx context.Context, arg GetWorkerDailyStatsParams) ([]WorkerStatsDaily, error) {
	rows, err := q.db.QueryContext(ctx, getWorkerDailyStats, arg.WorkerID, arg.SUBSTR)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	items := []WorkerStatsDaily{}
	for rows.Next() {
		var i WorkerStatsDaily
		if err := rows.Scan(
			&i.ID,
			&i.WorkerID,
			&i.StatsDate,
			&i.TotalBatches,
			&i.TotalKeysScanned,
			&i.TotalDurationMs,
			&i.KeysPerSecondAvg,
			&i.KeysPerSecondMin,
			&i.KeysPerSecondMax,
			&i.ErrorCount,
		); err != nil {
			return nil, err
		}
		items = append(items, i)
	}
	if err := rows.Close(); err != nil {
		return nil, err
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const getWorkerLastPrefix = `-- name: GetWorkerLastPrefix :one
SELECT prefix_28, MAX(nonce_end) as highest_nonce
FROM jobs
WHERE worker_id = ?
GROUP BY prefix_28
ORDER BY MAX(nonce_end) DESC
LIMIT 1
`

type GetWorkerLastPrefixRow struct {
	Prefix28     []byte      `json:"prefix_28"`
	HighestNonce interface{} `json:"highest_nonce"`
}

// Tracks the last prefix assigned to a worker to enable vertical exhaustion
func (q *Queries) GetWorkerLastPrefix(ctx context.Context, workerID sql.NullString) (GetWorkerLastPrefixRow, error) {
	row := q.db.QueryRowContext(ctx, getWorkerLastPrefix, workerID)
	var i GetWorkerLastPrefixRow
	err := row.Scan(&i.Prefix28, &i.HighestNonce)
	return i, err
}

const getWorkerLifetimeStats = `-- name: GetWorkerLifetimeStats :one
SELECT worker_id, worker_type, total_batches, total_keys_scanned, total_duration_ms, keys_per_second_avg, keys_per_second_best, keys_per_second_worst, first_seen_at, last_seen_at FROM worker_stats_lifetime
WHERE worker_id = ? LIMIT 1
`

func (q *Queries) GetWorkerLifetimeStats(ctx context.Context, workerID string) (WorkerStatsLifetime, error) {
	row := q.db.QueryRowContext(ctx, getWorkerLifetimeStats, workerID)
	var i WorkerStatsLifetime
	err := row.Scan(
		&i.WorkerID,
		&i.WorkerType,
		&i.TotalBatches,
		&i.TotalKeysScanned,
		&i.TotalDurationMs,
		&i.KeysPerSecondAvg,
		&i.KeysPerSecondBest,
		&i.KeysPerSecondWorst,
		&i.FirstSeenAt,
		&i.LastSeenAt,
	)
	return i, err
}

const getWorkerMonthlyStats = `-- name: GetWorkerMonthlyStats :many
SELECT id, worker_id, stats_month, total_batches, total_keys_scanned, total_duration_ms, keys_per_second_avg, keys_per_second_min, keys_per_second_max, error_count FROM worker_stats_monthly
WHERE worker_id = ? AND stats_month >= ?
ORDER BY stats_month DESC
`

type GetWorkerMonthlyStatsParams struct {
	WorkerID   string `json:"worker_id"`
	StatsMonth string `json:"stats_month"`
}

func (q *Queries) GetWorkerMonthlyStats(ctx context.Context, arg GetWorkerMonthlyStatsParams) ([]WorkerStatsMonthly, error) {
	rows, err := q.db.QueryContext(ctx, getWorkerMonthlyStats, arg.WorkerID, arg.StatsMonth)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	items := []WorkerStatsMonthly{}
	for rows.Next() {
		var i WorkerStatsMonthly
		if err := rows.Scan(
			&i.ID,
			&i.WorkerID,
			&i.StatsMonth,
			&i.TotalBatches,
			&i.TotalKeysScanned,
			&i.TotalDurationMs,
			&i.KeysPerSecondAvg,
			&i.KeysPerSecondMin,
			&i.KeysPerSecondMax,
			&i.ErrorCount,
		); err != nil {
			return nil, err
		}
		items = append(items, i)
	}
	if err := rows.Close(); err != nil {
		return nil, err
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const getWorkerStats = `-- name: GetWorkerStats :many
SELECT 
    w.id,
    w.worker_type,
    w.total_keys_scanned,
    w.last_seen,
    COUNT(j.id) as total_jobs,
    SUM(CASE WHEN j.status = 'processing' THEN 1 ELSE 0 END) as active_jobs,
    SUM(CASE WHEN j.status = 'completed' THEN 1 ELSE 0 END) as completed_jobs
FROM workers w
LEFT JOIN jobs j ON j.worker_id = w.id
GROUP BY w.id
ORDER BY w.total_keys_scanned DESC
LIMIT ?
`

type GetWorkerStatsRow struct {
	ID               string          `json:"id"`
	WorkerType       string          `json:"worker_type"`
	TotalKeysScanned sql.NullInt64   `json:"total_keys_scanned"`
	LastSeen         time.Time       `json:"last_seen"`
	TotalJobs        int64           `json:"total_jobs"`
	ActiveJobs       sql.NullFloat64 `json:"active_jobs"`
	CompletedJobs    sql.NullFloat64 `json:"completed_jobs"`
}

// Get statistics per worker
func (q *Queries) GetWorkerStats(ctx context.Context, limit int64) ([]GetWorkerStatsRow, error) {
	rows, err := q.db.QueryContext(ctx, getWorkerStats, limit)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	items := []GetWorkerStatsRow{}
	for rows.Next() {
		var i GetWorkerStatsRow
		if err := rows.Scan(
			&i.ID,
			&i.WorkerType,
			&i.TotalKeysScanned,
			&i.LastSeen,
			&i.TotalJobs,
			&i.ActiveJobs,
			&i.CompletedJobs,
		); err != nil {
			return nil, err
		}
		items = append(items, i)
	}
	if err := rows.Close(); err != nil {
		return nil, err
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const getWorkersByType = `-- name: GetWorkersByType :many
SELECT id, worker_type, last_seen, total_keys_scanned, metadata, created_at, updated_at FROM workers
WHERE worker_type = ?
ORDER BY last_seen DESC
`

// Get all workers of a specific type
func (q *Queries) GetWorkersByType(ctx context.Context, workerType string) ([]Worker, error) {
	rows, err := q.db.QueryContext(ctx, getWorkersByType, workerType)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	items := []Worker{}
	for rows.Next() {
		var i Worker
		if err := rows.Scan(
			&i.ID,
			&i.WorkerType,
			&i.LastSeen,
			&i.TotalKeysScanned,
			&i.Metadata,
			&i.CreatedAt,
			&i.UpdatedAt,
		); err != nil {
			return nil, err
		}
		items = append(items, i)
	}
	if err := rows.Close(); err != nil {
		return nil, err
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const insertResult = `-- name: InsertResult :one
INSERT INTO results (private_key, address, worker_id, job_id, nonce_found)
VALUES (?, ?, ?, ?, ?)
RETURNING id, private_key, address, worker_id, job_id, nonce_found, found_at
`

type InsertResultParams struct {
	PrivateKey string `json:"private_key"`
	Address    string `json:"address"`
	WorkerID   string `json:"worker_id"`
	JobID      int64  `json:"job_id"`
	NonceFound int64  `json:"nonce_found"`
}

// Insert a new result (found key)
func (q *Queries) InsertResult(ctx context.Context, arg InsertResultParams) (Result, error) {
	row := q.db.QueryRowContext(ctx, insertResult,
		arg.PrivateKey,
		arg.Address,
		arg.WorkerID,
		arg.JobID,
		arg.NonceFound,
	)
	var i Result
	err := row.Scan(
		&i.ID,
		&i.PrivateKey,
		&i.Address,
		&i.WorkerID,
		&i.JobID,
		&i.NonceFound,
		&i.FoundAt,
	)
	return i, err
}

const leaseBatch = `-- name: LeaseBatch :execrows
UPDATE jobs
SET 
    status = 'processing',
    worker_id = ?,
    worker_type = ?,
    expires_at = datetime('now', 'utc', '+' || ? || ' seconds')
WHERE id = ? 
  AND (status = 'pending' OR (status = 'processing' AND (expires_at < datetime('now', 'utc') OR worker_id IS NULL)))
`

type LeaseBatchParams struct {
	WorkerID     sql.NullString `json:"worker_id"`
	WorkerType   sql.NullString `json:"worker_type"`
	LeaseSeconds sql.NullString `json:"lease_seconds"`
	ID           int64          `json:"id"`
}

// Lease an existing batch to a worker
func (q *Queries) LeaseBatch(ctx context.Context, arg LeaseBatchParams) (int64, error) {
	result, err := q.db.ExecContext(ctx, leaseBatch,
		arg.WorkerID,
		arg.WorkerType,
		arg.LeaseSeconds,
		arg.ID,
	)
	if err != nil {
		return 0, err
	}
	return result.RowsAffected()
}

const leaseMacroJob = `-- name: LeaseMacroJob :execrows
UPDATE jobs
SET status = 'processing',
        worker_id = ?,
        worker_type = ?,
        expires_at = datetime('now', 'utc', '+' || ? || ' seconds')
WHERE id = ?
    AND status != 'completed'
    AND (worker_id IS NULL OR expires_at < datetime('now', 'utc'))
`

type LeaseMacroJobParams struct {
	WorkerID     sql.NullString `json:"worker_id"`
	WorkerType   sql.NullString `json:"worker_type"`
	LeaseSeconds sql.NullString `json:"lease_seconds"`
	ID           int64          `json:"id"`
}

// Lease an existing macro job to a worker (if not completed and available)
func (q *Queries) LeaseMacroJob(ctx context.Context, arg LeaseMacroJobParams) (int64, error) {
	result, err := q.db.ExecContext(ctx, leaseMacroJob,
		arg.WorkerID,
		arg.WorkerType,
		arg.LeaseSeconds,
		arg.ID,
	)
	if err != nil {
		return 0, err
	}
	return result.RowsAffected()
}

const recordWorkerStats = `-- name: RecordWorkerStats :exec
INSERT INTO worker_history (
    worker_id, worker_type, job_id, batch_size, keys_scanned, duration_ms, keys_per_second, prefix_28, nonce_start, nonce_end, finished_at, error_message
)
VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
`

type RecordWorkerStatsParams struct {
	WorkerID      string          `json:"worker_id"`
	WorkerType    sql.NullString  `json:"worker_type"`
	JobID         sql.NullInt64   `json:"job_id"`
	BatchSize     sql.NullInt64   `json:"batch_size"`
	KeysScanned   sql.NullInt64   `json:"keys_scanned"`
	DurationMs    sql.NullInt64   `json:"duration_ms"`
	KeysPerSecond sql.NullFloat64 `json:"keys_per_second"`
	Prefix28      []byte          `json:"prefix_28"`
	NonceStart    sql.NullInt64   `json:"nonce_start"`
	NonceEnd      sql.NullInt64   `json:"nonce_end"`
	FinishedAt    time.Time       `json:"finished_at"`
	ErrorMessage  sql.NullString  `json:"error_message"`
}

// Insert a raw worker history record (tier 1)
func (q *Queries) RecordWorkerStats(ctx context.Context, arg RecordWorkerStatsParams) error {
	_, err := q.db.ExecContext(ctx, recordWorkerStats,
		arg.WorkerID,
		arg.WorkerType,
		arg.JobID,
		arg.BatchSize,
		arg.KeysScanned,
		arg.DurationMs,
		arg.KeysPerSecond,
		arg.Prefix28,
		arg.NonceStart,
		arg.NonceEnd,
		arg.FinishedAt,
		arg.ErrorMessage,
	)
	return err
}

const updateCheckpoint = `-- name: UpdateCheckpoint :exec
UPDATE jobs
SET 
    current_nonce = ?,
    keys_scanned = ?,
    duration_ms = ?,
    last_checkpoint_at = datetime('now', 'utc')
WHERE id = ? AND worker_id = ? AND status = 'processing'
`

type UpdateCheckpointParams struct {
	CurrentNonce sql.NullInt64  `json:"current_nonce"`
	KeysScanned  sql.NullInt64  `json:"keys_scanned"`
	DurationMs   sql.NullInt64  `json:"duration_ms"`
	ID           int64          `json:"id"`
	WorkerID     sql.NullString `json:"worker_id"`
}

// Update job progress checkpoint
func (q *Queries) UpdateCheckpoint(ctx context.Context, arg UpdateCheckpointParams) error {
	_, err := q.db.ExecContext(ctx, updateCheckpoint,
		arg.CurrentNonce,
		arg.KeysScanned,
		arg.DurationMs,
		arg.ID,
		arg.WorkerID,
	)
	return err
}

const updateWorkerKeyCount = `-- name: UpdateWorkerKeyCount :exec
UPDATE workers
SET total_keys_scanned = total_keys_scanned + ?
WHERE id = ?
`

type UpdateWorkerKeyCountParams struct {
	TotalKeysScanned sql.NullInt64 `json:"total_keys_scanned"`
	ID               string        `json:"id"`
}

// Update worker's total key count
func (q *Queries) UpdateWorkerKeyCount(ctx context.Context, arg UpdateWorkerKeyCountParams) error {
	_, err := q.db.ExecContext(ctx, updateWorkerKeyCount, arg.TotalKeysScanned, arg.ID)
	return err
}

const upsertWorker = `-- name: UpsertWorker :exec
INSERT INTO workers (id, worker_type, last_seen, metadata, updated_at)
VALUES (?, ?, datetime('now', 'utc'), ?, datetime('now','utc'))
ON CONFLICT(id) DO UPDATE SET
    last_seen = datetime('now', 'utc'),
    metadata = excluded.metadata,
    updated_at = datetime('now','utc')
`

type UpsertWorkerParams struct {
	ID         string         `json:"id"`
	WorkerType string         `json:"worker_type"`
	Metadata   sql.NullString `json:"metadata"`
}

// Insert or update worker heartbeat
func (q *Queries) UpsertWorker(ctx context.Context, arg UpsertWorkerParams) error {
	_, err := q.db.ExecContext(ctx, upsertWorker, arg.ID, arg.WorkerType, arg.Metadata)
	return err
}
