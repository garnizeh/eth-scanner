# A01-T050: Implement multi-tier worker statistics tables with automatic aggregation

**Phase:** A01 - Performance & Optimization (Adhoc)  
**Status:** Not Started  
**Priority:** High  
**Dependencies:** A01-T040  
**Estimated Effort:** Large (3h+)

---

## Description

Create a **four-tier statistics architecture** to store worker performance metrics at different time scales. This design prevents unbounded database growth while preserving long-term historical data through automatic aggregation.

**Architecture:**
- Tier 1: `worker_history` - Raw detail (10K records globally, configurable)
- Tier 2: `worker_stats_daily` - Daily aggregation (1K records per worker)
- Tier 3: `worker_stats_monthly` - Monthly aggregation (1K records per worker)  
- Tier 4: `worker_stats_lifetime` - Lifetime totals (1 record per worker, forever)

Data automatically cascades through tiers via SQLite triggers as it ages out.

Since the project is not in production, we will add all tables directly to the existing schema file.

---

## Acceptance Criteria

- [ ] Add `worker_history` table to `internal/database/sql/001_schema.sql`
- [ ] Add `worker_stats_daily` table for daily aggregation per worker
- [ ] Add `worker_stats_monthly` table for monthly aggregation per worker
- [ ] Add `worker_stats_lifetime` table for cumulative totals
- [ ] Add indexes for all tables (worker_id, dates, worker_type)
- [ ] Implement `aggregate_before_prune_history` trigger (history → daily/monthly/lifetime)
- [ ] Implement `prune_daily_stats_per_worker` trigger (cap at 1000 per worker_id)
- [ ] Implement `prune_monthly_stats_per_worker` trigger (cap at 1000 per worker_id)
- [ ] Add sqlc queries for inserting stats at all tiers
- [ ] Add sqlc queries for dashboard data retrieval (recent, daily, monthly, lifetime)
- [ ] Run `sqlc generate` and verify generated code
- [ ] Write unit tests for stats insertion at each tier
- [ ] Write unit tests verifying retention limits work per worker (not globally)
- [ ] Write unit tests verifying automatic aggregation triggers fire correctly

---

## Implementation Notes

**Four-Tier Architecture:**

1. **worker_history** (Tier 1 - Raw Detail):
   - Individual batch records
   - Global retention limit (default: 10000)
   - Real-time dashboard queries
   - Fields: worker_id, worker_type, job_id, batch_size, keys_scanned, duration_ms, keys_per_second, prefix_28, nonce ranges, timestamps, error_message

2. **worker_stats_daily** (Tier 2 - Daily Aggregation):
   - One record per worker per day
   - Retention: 1000 most recent records **per worker_id**
   - Aggregated metrics: total_batches, total_keys_scanned, avg/min/max keys_per_second, error counts
   - UNIQUE constraint on (worker_id, stats_date)

3. **worker_stats_monthly** (Tier 3 - Monthly Aggregation):
   - One record per worker per month
   - Retention: 1000 most recent records **per worker_id**
   - Same aggregated metrics as daily
   - UNIQUE constraint on (worker_id, stats_month)

4. **worker_stats_lifetime** (Tier 4 - Lifetime Totals):
   - One record per worker (PRIMARY KEY on worker_id)
   - No retention limit (permanent)
   - Cumulative totals: total_batches, total_keys_scanned, total_duration_ms
   - Performance stats: avg/best/worst keys_per_second
   - Activity tracking: first_seen_at, last_seen_at

**Cascading Aggregation Triggers:**

```sql
-- Example trigger structure (simplified)
CREATE TRIGGER aggregate_before_prune_history
BEFORE DELETE ON worker_history
FOR EACH ROW
BEGIN
    -- Update daily stats (INSERT ... ON CONFLICT DO UPDATE)
    -- Update monthly stats (INSERT ... ON CONFLICT DO UPDATE)
    -- Update lifetime stats (INSERT ... ON CONFLICT DO UPDATE)
END;

-- Per-worker pruning (not global)
CREATE TRIGGER prune_daily_stats_per_worker
AFTER INSERT ON worker_stats_daily
FOR EACH ROW
WHEN (SELECT COUNT(*) FROM worker_stats_daily WHERE worker_id = NEW.worker_id) > 1000
BEGIN
    -- Aggregate oldest records to monthly/lifetime
    -- Delete oldest records for THIS worker only
END;
```

**Key Design Points:**
- Pruning is **per worker_id**, not global (each worker maintains 1000 daily + 1000 monthly records)
- Before deleting, data is aggregated to higher tiers (no data loss)
- Triggers fire automatically (no background job needed)
- SQLite UPSERT syntax: `INSERT ... ON CONFLICT(...) DO UPDATE SET ...`

**Sqlc Queries to Implement:**

```sql
-- name: RecordWorkerStats :exec
INSERT INTO worker_history (...) VALUES (...);

-- name: GetRecentWorkerHistory :many
SELECT * FROM worker_history
WHERE finished_at > datetime('now', ?)
ORDER BY finished_at DESC LIMIT ?;

-- name: GetWorkerDailyStats :many
SELECT * FROM worker_stats_daily
WHERE worker_id = ? AND stats_date >= ?
ORDER BY stats_date DESC;

-- name: GetWorkerMonthlyStats :many
SELECT * FROM worker_stats_monthly
WHERE worker_id = ? AND stats_month >= ?
ORDER BY stats_month DESC;

-- name: GetWorkerLifetimeStats :one
SELECT * FROM worker_stats_lifetime
WHERE worker_id = ? LIMIT 1;

-- name: GetAllWorkerLifetimeStats :many
SELECT * FROM worker_stats_lifetime
ORDER BY total_keys_scanned DESC;
```

**Retention Mechanism:**
- The trigger prune limit will use a placeholder initially (1000 for daily/monthly)
- In A01-T055, we'll add config support for `WORKER_DAILY_STATS_LIMIT` and `WORKER_MONTHLY_STATS_LIMIT`
- Triggers will be recreated at DB init with configured values

**Reference:**
- See `docs/architecture/db-optimization-proposal.md` section 2.B

---

## Testing Strategy

**Unit Tests:**
- Test: Insert stats record, verify all fields stored correctly in worker_history
- Test: Insert stats for worker A, trigger aggregation to daily, verify daily record created
- Test: Insert stats spanning 2 days, verify 2 daily records for same worker
- Test: Insert 1001 daily records for worker A, verify oldest is deleted (count = 1000)
- Test: Verify other workers' daily stats are NOT affected when worker A is pruned
- Test: Insert 1001 monthly records for worker B, verify B has 1000, worker A unaffected
- Test: Verify lifetime stats accumulate correctly across multiple inserts
- Test: Query stats by worker_id at each tier
- Test: Query stats by date range (daily/monthly)

**Integration Tests:**
- Test: Full cascade - insert history → prune → verify daily created → prune daily → verify monthly created
- Test: Multiple workers concurrently inserting stats, verify per-worker isolation
- Test: Verify aggregated metrics match sum of underlying data before deletion

**Performance Tests:**
- Benchmark: Measure trigger overhead on history insertion
- Benchmark: Measure pruning performance with 10K+ records per worker
- Verify: Query performance on daily/monthly tables with max retention reached

---

## Progress Log

### [Date] - [Status Update]
- [Notes on implementation progress]
