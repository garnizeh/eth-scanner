# A01-T030: Worker dynamic batch size adjustment based on target duration

**Phase:** A01 - Performance & Optimization (Adhoc)  
**Status:** Not Started  
**Priority:** Medium  
**Dependencies:** None  
**Estimated Effort:** Medium (1-3h)

---

## Description

Implement adaptive batch sizing in the PC worker that adjusts the `requested_batch_size` based on actual job completion time compared to a configurable target duration.

**Problem:**
- Current workers request a static batch size calculated at startup based on `runtime.NumCPU()` and estimated throughput.
- Actual throughput varies based on CPU model, thermal throttling, background load, and crypto library performance.
- Fixed batch sizes may result in jobs that complete too quickly (inefficient API round-trips) or too slowly (increased risk of lease expiration).

**Solution:**
- Track the time taken to complete each batch.
- Compare actual duration to a configurable target duration (default: 1 hour).
- Adjust the next `requested_batch_size` using a simple proportional controller:
  ```
  new_batch_size = current_batch_size * (target_duration / actual_duration)
  ```
- Apply min/max bounds to prevent extreme values.
- Store the adjusted batch size in worker state for the next lease request.

**Example:**
- Target duration: 1 hour (3600 seconds)
- Batch 1: requested 1,000,000 keys, took 30 minutes (1800 seconds)
- Worker calculates: `new_size = 1,000,000 * (3600 / 1800) = 2,000,000`
- Batch 2: worker requests 2,000,000 keys
- Batch 2 completes in 55 minutes (close to target)
- Worker calculates: `new_size = 2,000,000 * (3600 / 3300) ≈ 2,181,818`
- Converges toward optimal batch size over several iterations

---

## Acceptance Criteria

- [ ] Worker configuration includes `TARGET_JOB_DURATION` (default: 1 hour = 3600 seconds)
- [ ] Worker configuration includes `MIN_BATCH_SIZE` (default: 100,000) and `MAX_BATCH_SIZE` (default: 10,000,000)
- [ ] Worker tracks start time when beginning a batch and end time when completing
- [ ] After batch completion, worker calculates adjustment factor: `target_duration / actual_duration`
- [ ] Worker updates internal `batch_size` state for next lease request
- [ ] Batch size is clamped to configured min/max bounds
- [ ] Initial batch size can be set via config or calculated from `runtime.NumCPU()` * estimated throughput
- [ ] Unit tests verify batch size adjustment logic with mock durations
- [ ] Integration test confirms worker converges to target duration over multiple batches

---

## Implementation Notes

**Key Points:**
- Add configuration fields to `internal/worker/config.go`:
  - `TargetJobDurationSeconds` (default: 3600)
  - `MinBatchSize` (default: 100000)
  - `MaxBatchSize` (default: 10000000)
- Modify worker main loop in `cmd/worker-pc/main.go` or `internal/worker/worker.go`:
  1. Start timer before processing batch
  2. Complete batch and stop timer
  3. Calculate adjustment factor
  4. Update `batchSize` state variable
  5. Use updated `batchSize` in next lease request
- Use exponential smoothing (optional) to avoid overcorrection from outliers:
  ```go
  alpha := 0.5  // smoothing factor
  adjustment := targetDuration / actualDuration
  newBatchSize = uint32(float64(currentBatchSize) * (alpha*adjustment + (1-alpha)*1.0))
  ```
- Log batch size adjustments at INFO level for monitoring

**Code outline:**
```go
// internal/worker/worker.go (or cmd/worker-pc/main.go)
type Worker struct {
    cfg       *config.Config
    batchSize uint32
    // ... other fields
}

func (w *Worker) Run(ctx context.Context) {
    // Initialize batch size from config or estimate
    w.batchSize = w.cfg.InitialBatchSize
    
    for {
        // Lease batch
        job := leaseBatch(ctx, w.cfg.WorkerID, w.batchSize)
        if job == nil {
            time.Sleep(5 * time.Second)
            continue
        }
        
        // Process batch and measure duration
        start := time.Now()
        processBatch(ctx, job)
        duration := time.Since(start)
        
        // Report completion
        completeBatch(ctx, job.ID)
        
        // Adjust batch size for next iteration
        w.adjustBatchSize(duration)
    }
}

func (w *Worker) adjustBatchSize(actualDuration time.Duration) {
    target := time.Duration(w.cfg.TargetJobDurationSeconds) * time.Second
    actual := actualDuration.Seconds()
    targetSec := target.Seconds()
    
    if actual <= 0 {
        return // avoid division by zero
    }
    
    adjustment := targetSec / actual
    newSize := uint32(float64(w.batchSize) * adjustment)
    
    // Clamp to min/max bounds
    if newSize < w.cfg.MinBatchSize {
        newSize = w.cfg.MinBatchSize
    }
    if newSize > w.cfg.MaxBatchSize {
        newSize = w.cfg.MaxBatchSize
    }
    
    log.Printf("INFO: batch size adjusted: %d -> %d (duration: %.1fs, target: %.1fs)",
        w.batchSize, newSize, actual, targetSec)
    
    w.batchSize = newSize
}
```

**Trade-offs:**
- **Pro:** Workers adapt to actual hardware performance automatically
- **Pro:** Reduces API round-trip overhead by requesting appropriately-sized batches
- **Pro:** Minimizes risk of lease expiration by avoiding excessively large batches
- **Con:** Adds slight complexity to worker state management
- **Con:** May oscillate if throughput is highly variable (mitigated by exponential smoothing or min adjustment threshold)

**Mitigations:**
- Use conservative min/max bounds to prevent pathological batch sizes
- Log adjustments for visibility and debugging
- Consider adding a "damping factor" to slow down aggressive adjustments

---

## Testing

**How to verify this task is complete:**

1. **Unit Test:** Test batch size adjustment calculation
   ```bash
   go test ./internal/worker/... -run TestAdjustBatchSize -v
   ```

2. **Unit Test:** Test clamping to min/max bounds
   ```bash
   go test ./internal/worker/... -run TestBatchSizeClamping -v
   ```

3. **Integration Test:** Run worker and observe batch size convergence in logs
   ```bash
   # Terminal 1: Start master
   make run-master
   
   # Terminal 2: Start worker with small initial batch
   WORKER_INITIAL_BATCH_SIZE=10000 WORKER_TARGET_DURATION=300 make run-worker
   
   # Observe logs for batch size adjustments converging toward 5-minute batches
   ```

4. **Expected Outcome:**
   - Worker logs show batch size increasing/decreasing over several iterations
   - Batch durations converge toward configured target duration
   - Batch sizes remain within min/max bounds

---

## References

- **SDD:** `docs/architecture/system-design-document.md` (Dynamic Batching Strategy)
- **Worker Config:** `internal/worker/config.go`
- **Worker Main Loop:** `cmd/worker-pc/main.go` or `internal/worker/worker.go`
- **Related Tasks:** P05-T070 (initial batch size calculator), A01-T010 (prefix affinity)

---

## Progress Log

_(To be filled during implementation)_

---

## Notes

**Why this matters:**
- Static batch sizing is suboptimal for heterogeneous hardware (different CPU counts, speeds)
- Adaptive sizing improves efficiency and reduces lease expiration risk
- Enables the same worker binary to run optimally on a range of hardware configurations

**Design considerations:**
- **Proportional control:** Simple `new = old * (target / actual)` works well for stable systems
- **Exponential smoothing:** Use weighted average to reduce overcorrection: `alpha * adjustment + (1-alpha) * 1.0`
- **Min adjustment threshold:** Only adjust if `abs(actual - target) > threshold` to avoid thrashing

**Future enhancements:**
- Add metrics for batch duration and size over time (Prometheus histogram)
- Implement PID controller (Proportional-Integral-Derivative) for tighter convergence
- Consider adaptive checkpoint frequency based on batch size (larger batches → more frequent checkpoints)
