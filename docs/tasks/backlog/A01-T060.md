# A01-T060: Update Master API to record worker statistics on checkpoint/complete

**Phase:** A01 - Performance & Optimization (Adhoc)  
**Status:** Not Started  
**Priority:** High  
**Dependencies:** A01-T050, A01-T055  
**Estimated Effort:** Medium (1-3h)

---

## Description

Modify the Master API endpoints (`/checkpoint` and `/complete`) to record detailed worker performance statistics to the `worker_history` table on every checkpoint and completion event. This populates the dashboard-ready metrics table while maintaining the lean `jobs` table.

---

## Acceptance Criteria

- [ ] Update `internal/server/checkpoint.go` to insert worker_history record on each checkpoint
- [ ] Update `internal/server/complete.go` to insert worker_history record on job completion
- [ ] Calculate `keys_per_second` from `keys_scanned` and `duration_ms` (or receive from client)
- [ ] Extract `worker_type` from request or job metadata
- [ ] Handle errors in worker_history insertion gracefully (log but don't fail the checkpoint/complete operation)
- [ ] Add request fields: `started_at`, `duration_ms`, `keys_scanned` (if not already present)
- [ ] Update API documentation/OpenAPI spec with new fields
- [ ] Write unit tests for checkpoint endpoint with stats recording
- [ ] Write unit tests for complete endpoint with stats recording
- [ ] Write integration test verifying stats are queryable after checkpoint

---

## Implementation Notes

**Checkpoint Request Payload (updated):**
```go
type CheckpointRequest struct {
    CurrentNonce  uint64    `json:"current_nonce"`
    KeysScanned   uint64    `json:"keys_scanned"`
    StartedAt     time.Time `json:"started_at"`  // When this batch started
    DurationMs    int64     `json:"duration_ms"` // Time since started_at
}
```

**Complete Request Payload (updated):**
```go
type CompleteRequest struct {
    KeysScanned   uint64    `json:"keys_scanned"`
    StartedAt     time.Time `json:"started_at"`
    DurationMs    int64     `json:"duration_ms"`
}
```

**Stats Recording Logic:**
```go
// In checkpoint handler
func (s *Server) handleCheckpoint(w http.ResponseWriter, r *http.Request) {
    // ... existing checkpoint logic ...
    
    // Record statistics
    keysPerSecond := calculateKeysPerSecond(req.KeysScanned, req.DurationMs)
    statsParams := database.RecordWorkerStatsParams{
        WorkerID:      job.WorkerID.String,
        WorkerType:    sql.NullString{String: job.WorkerType.String, Valid: job.WorkerType.Valid},
        JobID:         sql.NullInt64{Int64: job.ID, Valid: true},
        BatchSize:     int64(req.KeysScanned),
        KeysScanned:   int64(req.KeysScanned),
        DurationMs:    req.DurationMs,
        KeysPerSecond: keysPerSecond,
        Prefix28:      job.Prefix28,
        NonceStart:    sql.NullInt64{Int64: job.CurrentNonce.Int64, Valid: true},
        NonceEnd:      sql.NullInt64{Int64: int64(req.CurrentNonce), Valid: true},
        StartedAt:     req.StartedAt.Format(time.RFC3339),
    }
    
    if err := s.db.RecordWorkerStats(ctx, statsParams); err != nil {
        // Log error but don't fail the checkpoint
        log.Printf("WARNING: failed to record worker stats: %v", err)
    }
}

func calculateKeysPerSecond(keys uint64, durationMs int64) int64 {
    if durationMs <= 0 {
        return 0
    }
    return int64(float64(keys) / (float64(durationMs) / 1000.0))
}
```

**Reference:**
- See `docs/architecture/db-optimization-proposal.md` section 3, Phase 4

---

## Testing Strategy

- Unit test: Checkpoint with valid metrics records stats successfully
- Unit test: Complete with valid metrics records stats successfully
- Unit test: Stats insertion failure doesn't break checkpoint operation
- Unit test: Verify keys_per_second calculation accuracy
- Integration test: Checkpoint multiple times, verify N history records exist
- Integration test: Query worker_history after completion, verify data matches request

---

## Progress Log

### [Date] - [Status Update]
- [Notes on implementation progress]
