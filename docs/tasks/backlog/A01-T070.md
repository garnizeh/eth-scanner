# A01-T070: Integration testing and validation of optimized job management

**Phase:** A01 - Performance & Optimization (Adhoc)  
**Status:** Not Started  
**Priority:** High  
**Dependencies:** A01-T065  
**Estimated Effort:** Medium (1-3h)

---

## Description

Comprehensive integration testing and validation of the optimized job management system with long-lived jobs and **multi-tier worker statistics**. Verify database size remains bounded, performance is improved, and all four statistics tiers work correctly with their respective retention limits under realistic load.

Since we're modifying the schema directly (no production deployment), we can fully validate the new approach without migration concerns.

---

## Acceptance Criteria

- [ ] Write end-to-end test: Single worker completes full job with multiple checkpoints
- [ ] Write end-to-end test: Multiple workers processing different prefixes concurrently
- [ ] Write end-to-end test: Worker crash and resume from last checkpoint
- [ ] Write end-to-end test: Verify jobs table size remains constant (no growth per batch)
- [ ] Write load test: 15,000 checkpoints with WORKER_HISTORY_LIMIT=10000, verify globally capped
- [ ] Write load test: Insert 1,500 daily records for worker A, verify exactly 1,000 remain (per-worker cap)
- [ ] Write load test: Insert 1,500 monthly records for worker B, verify exactly 1,000 remain (per-worker cap)
- [ ] Write load test: Verify worker A's daily pruning doesn't affect worker B's daily stats
- [ ] Write test: Verify automatic aggregation (history → daily → monthly → lifetime)
- [ ] Write test: Verify daily stats are aggregated to monthly before deletion
- [ ] Write test: Verify lifetime stats accumulate correctly from all tiers
- [ ] Measure database file size before/after optimization (compare old vs new approach)
- [ ] Benchmark checkpoint throughput (checkpoints/second with all triggers active)
- [ ] Verify dashboard queries perform well at all tiers (history, daily, monthly, lifetime)
- [ ] Document performance improvements and storage savings in test results
- [ ] Update project documentation with optimization benefits and configuration guide

---

## Implementation Notes

**Test Scenarios:**

1. **Bounded Storage Test (Jobs Table):**
   - Start with empty database
   - Run worker with 20 checkpoints
   - Verify `jobs` table has exactly 1 row (the active job)
   - Old system would have 20 completed job rows
   - New system: 1 job row + stats in history tables

2. **Global Retention Test (worker_history):**
   ```go
   func TestWorkerHistoryGlobalRetention(t *testing.T) {
       // Set global limit to 100
       cfg.WorkerHistoryLimit = 100
       
       // Insert 150 checkpoint records from 3 different workers
       // Worker A: 60 records
       // Worker B: 50 records
       // Worker C: 40 records
       // Total: 150 records
       
       // Verify global count = 100 (oldest deleted regardless of worker)
       count := queryHistoryCount()
       assert.Equal(t, 100, count)
   }
   ```

3. **Per-Worker Daily Retention Test:**
   ```go
   func TestWorkerDailyStatsPerWorkerRetention(t *testing.T) {
       // Set limit to 1000 per worker
       cfg.WorkerDailyStatsLimit = 1000
       
       // Insert 1500 daily records for worker A (spanning 1500 days)
       // Insert 800 daily records for worker B (spanning 800 days)
       
       // Verify worker A has exactly 1000 records
       countA := queryDailyCount("worker-a")
       assert.Equal(t, 1000, countA)
       
       // Verify worker B has exactly 800 records (under limit)
       countB := queryDailyCount("worker-b")
       assert.Equal(t, 800, countB)
       
       // Total should be 1800 (not globally capped)
   }
   ```

4. **Per-Worker Monthly Retention Test:**
   ```go
   func TestWorkerMonthlyStatsPerWorkerRetention(t *testing.T) {
       // Similar to daily, but with monthly data
       // Verify each worker maintains separate 1000-record cap
   }
   ```

5. **Cascading Aggregation Test:**
   ```go
   func TestAutomaticAggregation(t *testing.T) {
       // Insert 100 history records for worker A on 2026-02-16
       // Force prune (insert until global limit exceeded)
       
       // Verify daily stats for 2026-02-16 has aggregated data
       daily := getDailyStats("worker-a", "2026-02-16")
       assert.Equal(t, 100, daily.TotalBatches)
       assert.Equal(t, sumKeysScanned, daily.TotalKeysScanned)
       
       // Verify monthly stats for 2026-02 has aggregated data
       monthly := getMonthlyStats("worker-a", "2026-02")
       assert.GreaterOrEqual(t, monthly.TotalBatches, 100)
       
       // Verify lifetime stats has cumulative totals
       lifetime := getLifetimeStats("worker-a")
       assert.GreaterOrEqual(t, lifetime.TotalBatches, 100)
   }
   ```

6. **Worker Isolation Test:**
   ```go
   func TestWorkerIsolation(t *testing.T) {
       // Insert 1200 daily records for worker A
       // Insert 500 daily records for worker B
       
       // Verify worker A pruned to 1000
       assert.Equal(t, 1000, countDaily("worker-a"))
       
       // Verify worker B untouched (500 < limit)
       assert.Equal(t, 500, countDaily("worker-b"))
   }
   ```

7. **Crash Recovery Test:**
   ```go
   func TestWorkerCrashRecovery(t *testing.T) {
       // Worker 1 leases job, checkpoints at nonce=1M (stats recorded)
       // Simulate crash (lease expires)
       
       // Verify stats still in worker_history
       // Worker 2 leases same job
       // Verify Worker 2 starts from nonce=1M (not 0)
       // Verify both workers' stats are tracked separately
   }
   ```

**Database Size Validation:**
```bash
# Simulate old behavior (estimate)
# 1000 batches = 1000 job rows + indexes
# Each job row: ~200 bytes
# Total: 200 KB for jobs alone

# New approach
# 1000 batches = 1 job row + stats distributed across tiers
# 1 job row: ~200 bytes
# worker_history (capped at 10K globally): ~2 MB max
# worker_stats_daily (1K per worker × avg 10 workers): ~200 KB
# worker_stats_monthly (1K per worker × 10 workers): ~200 KB
# worker_stats_lifetime (1 row per worker): ~2 KB
# Total maximum: ~2.6 MB (bounded, vs unbounded growth)

# With 1M checkpoints over time:
# Old: ~200 MB (1M × 200 bytes)
# New: ~2.6 MB (bounded by retention limits)
# Savings: 98.7% reduction
```

**Documentation Updates:**
- Update README.md with WORKER_HISTORY_LIMIT configuration
- Document performance improvements in `docs/worker-pc-benchmarks.md`
- Add troubleshooting guide for retention tuning
- Update system design document with optimized architecture

**Reference:**
- See `docs/architecture/db-optimization-proposal.md` section 4 (Benefits)

---

## Testing Strategy

- Run full test suite: `go test ./... -v`
- Run load test: `go test ./internal/server -run TestWorkerHistoryLoad -v`
- Run benchmark: `go test ./internal/server -bench=BenchmarkCheckpoint -benchmem`
- Manual testing: Run worker for 1 hour, inspect database state
- Verify no memory leaks with extended runs
- Check database file size growth over time

**Success Metrics:**
- Jobs table size: O(1) - no growth with more batches
- worker_history: Bounded globally (default 10K records max)
- worker_stats_daily: Bounded per worker (default 1K records per worker)
- worker_stats_monthly: Bounded per worker (default 1K records per worker)
- worker_stats_lifetime: O(workers) - 1 record per worker
- Checkpoint latency: < 10ms p99 (with all 4 tiers + triggers active)
- No performance degradation after 100K+ total checkpoints across all workers
- Database file size: Remains under 10 MB even with months of continuous operation
- Aggregation accuracy: 100% - sum of aggregated data matches original before pruning

---

## Progress Log

### [Date] - [Status Update]
- [Notes on implementation progress]
