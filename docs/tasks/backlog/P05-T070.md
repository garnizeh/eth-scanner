# P05-T070: Implement batch size calculator

**Phase:** P05 - PC Worker - Core Implementation  
**Status:** Not Started  
**Priority:** High  
**Dependencies:** None  
**Estimated Effort:** Small

---

## Description

Implement a function to calculate the optimal batch size (nonce range) for a PC worker based on its computational capacity. The batch size should target approximately 1 hour of work to balance lease overhead with resilience to worker failures.

## Acceptance Criteria

- [ ] `CalculateBatchSize(keysPerSecond uint64, targetDuration time.Duration)` function exists
- [ ] Function returns batch size as `uint32`
- [ ] Batch size calculation: `keysPerSecond × targetDuration.Seconds()`
- [ ] Result is clamped to maximum of `2^32 - 1` (full 4-byte nonce range)
- [ ] Default target duration is 1 hour (3600 seconds)
- [ ] Function handles edge cases (zero throughput, overflow)
- [ ] Optionally: benchmark function to measure actual throughput on current hardware

## Implementation Notes

### Function Signature
```go
package worker

import (
    "runtime"
    "time"
)

// CalculateBatchSize computes the optimal batch size (nonce range)
// based on estimated throughput and target duration.
// Returns the batch size as uint32 (max 2^32 - 1).
func CalculateBatchSize(keysPerSecond uint64, targetDuration time.Duration) uint32 {
    targetSeconds := uint64(targetDuration.Seconds())
    batchSize := keysPerSecond * targetSeconds
    
    // Clamp to max uint32
    const maxBatchSize = uint64(0xFFFFFFFF) // 2^32 - 1 = 4,294,967,295
    if batchSize > maxBatchSize {
        return uint32(maxBatchSize)
    }
    
    // Handle zero throughput
    if batchSize == 0 {
        return 1000000 // Minimum batch size fallback
    }
    
    return uint32(batchSize)
}
```

### Throughput Estimation
For a PC worker, estimate throughput based on CPU cores:
```go
// EstimateThroughput runs a benchmark to measure actual scanning speed.
// Returns estimated keys per second.
func EstimateThroughput() uint64 {
    // Run a small benchmark (1 second of scanning)
    // Count how many keys are scanned
    // Return keys/sec
    // Example: return uint64(runtime.NumCPU()) * 100000 // 100k keys/sec per core
}
```

### Example Calculation
```
PC Worker Specs:
- CPU: 8 cores
- Estimated throughput: 800k keys/sec (100k per core)
- Target duration: 1 hour (3600 seconds)

Batch Size = 800,000 × 3,600 = 2,880,000,000 keys
```

This means the worker will request a nonce range of ~2.88 billion (out of max 4.29 billion).

### Dynamic Batch Sizing
The worker should measure its actual throughput during the first batch and adjust subsequent requests:
```go
type Worker struct {
    measuredThroughput uint64 // keys/sec
}

func (w *Worker) RequestBatch(ctx context.Context) (*JobLease, error) {
    batchSize := CalculateBatchSize(w.measuredThroughput, 1*time.Hour)
    return w.client.LeaseBatch(ctx, batchSize)
}
```

### Edge Cases
1. **Zero throughput:** Return a minimum batch size (e.g., 1 million keys)
2. **Overflow:** Clamp to `2^32 - 1` (maximum 4-byte nonce range)
3. **Very slow workers:** Even if throughput is low, ensure batch size is reasonable (at least 1 million)
4. **Very fast workers:** Cap at full nonce range (4.29 billion)

## Testing

```bash
cd /home/user/code/garnizeh/eth-scanner/go
go test ./internal/worker -v -run TestCalculateBatchSize
```

### Test Cases
- Normal throughput (800k keys/sec) with 1-hour target returns ~2.88B
- Zero throughput returns fallback minimum (1M)
- Very high throughput (overflow) returns max uint32 (4.29B)
- Custom target duration (30 minutes) returns proportional batch size
- EstimateThroughput returns reasonable value (> 0)

### Example Test
```go
func TestCalculateBatchSize(t *testing.T) {
    tests := []struct {
        name           string
        keysPerSecond  uint64
        targetDuration time.Duration
        expected       uint32
    }{
        {
            name:           "normal throughput",
            keysPerSecond:  800000,
            targetDuration: 1 * time.Hour,
            expected:       2880000000,
        },
        {
            name:           "zero throughput",
            keysPerSecond:  0,
            targetDuration: 1 * time.Hour,
            expected:       1000000, // fallback
        },
        {
            name:           "overflow",
            keysPerSecond:  5000000000,
            targetDuration: 1 * time.Hour,
            expected:       0xFFFFFFFF, // max uint32
        },
        {
            name:           "30 minutes",
            keysPerSecond:  800000,
            targetDuration: 30 * time.Minute,
            expected:       1440000000,
        },
    }
    
    for _, tt := range tests {
        t.Run(tt.name, func(t *testing.T) {
            result := CalculateBatchSize(tt.keysPerSecond, tt.targetDuration)
            if result != tt.expected {
                t.Errorf("expected %d, got %d", tt.expected, result)
            }
        })
    }
}
```

## References

- SDD: `docs/architecture/system-design-document.md` (Section 3.2: Dynamic Batching)
- Related tasks: P05-T080 (uses batch size in main loop), P06-T110 (benchmarking)
- Go stdlib: `runtime.NumCPU()` for core count
