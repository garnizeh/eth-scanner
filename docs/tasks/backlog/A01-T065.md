# A01-T065: Update PC Worker client to support long-lived jobs and metrics reporting

**Phase:** A01 - Performance & Optimization (Adhoc)  
**Status:** Not Started  
**Priority:** High  
**Dependencies:** A01-T060  
**Estimated Effort:** Medium (1-3h)

---

## Description

Update the PC Worker client implementation to work with the new long-lived job model. Instead of requesting a new job for every small batch, the worker should maintain a single job assignment and report progress via checkpoints, including detailed performance metrics for the worker_history table.

---

## Acceptance Criteria

- [ ] Update `cmd/worker-pc/main.go` to maintain job state across multiple internal batches
- [ ] Modify worker loop to process large jobs in small chunks locally
- [ ] Send checkpoint requests periodically (e.g., every N keys or M seconds) instead of completing immediately
- [ ] Include performance metrics in checkpoint/complete requests: `started_at`, `duration_ms`, `keys_scanned`
- [ ] Track batch start time and calculate duration before sending checkpoint
- [ ] Handle lease expiration gracefully (re-request work if checkpoint fails with 410 Gone)
- [ ] Update worker configuration to support checkpoint interval settings
- [ ] Write unit tests for metrics calculation (keys_scanned, duration_ms, throughput)
- [ ] Write integration test for full worker lifecycle with multiple checkpoints

---

## Implementation Notes

**Worker State Machine:**
```go
type WorkerState struct {
    JobID         int64
    Prefix28      []byte
    NonceStart    uint64
    NonceEnd      uint64
    CurrentNonce  uint64
    BatchStarted  time.Time
    KeysScanned   uint64
}
```

**Updated Worker Loop:**
```go
func (w *Worker) Run(ctx context.Context) error {
    for {
        // Request work (lease job)
        job, err := w.requestWork(ctx)
        if err != nil {
            return err
        }
        
        state := &WorkerState{
            JobID:        job.ID,
            Prefix28:     job.Prefix28,
            NonceStart:   job.NonceStart,
            NonceEnd:     job.NonceEnd,
            CurrentNonce: job.CurrentNonce,
        }
        
        // Process job in small batches
        for state.CurrentNonce < state.NonceEnd {
            state.BatchStarted = time.Now().UTC()
            state.KeysScanned = 0
            
            // Process internal batch (e.g., 1 million keys)
            batchSize := w.calculateBatchSize()
            endNonce := min(state.CurrentNonce + batchSize, state.NonceEnd)
            
            for nonce := state.CurrentNonce; nonce < endNonce; nonce++ {
                // Scan key
                w.scanKey(state.Prefix28, nonce)
                state.KeysScanned++
            }
            
            state.CurrentNonce = endNonce
            
            // Send checkpoint
            duration := time.Since(state.BatchStarted)
            if err := w.sendCheckpoint(ctx, state, duration); err != nil {
                // Handle lease expiration or errors
                if isLeaseExpired(err) {
                    break // Re-request work
                }
                return err
            }
            
            // Check if job complete
            if state.CurrentNonce >= state.NonceEnd {
                if err := w.sendComplete(ctx, state); err != nil {
                    return err
                }
                break
            }
        }
    }
}

func (w *Worker) sendCheckpoint(ctx context.Context, state *WorkerState, duration time.Duration) error {
    req := CheckpointRequest{
        CurrentNonce: state.CurrentNonce,
        KeysScanned:  state.KeysScanned,
        StartedAt:    state.BatchStarted,
        DurationMs:   duration.Milliseconds(),
    }
    return w.client.Checkpoint(ctx, state.JobID, req)
}
```

**Configuration:**
```go
type WorkerConfig struct {
    // ... existing fields ...
    CheckpointInterval time.Duration  // How often to checkpoint (default: 30s)
    InternalBatchSize  uint64         // Keys per internal batch (default: 1M)
}
```

**Reference:**
- See `docs/architecture/db-optimization-proposal.md` section 3, Phase 5

---

## Testing Strategy

- Unit test: Metrics calculation (duration_ms, keys_scanned)
- Unit test: Checkpoint interval logic
- Unit test: Handle lease expiration (re-request work)
- Integration test: Worker processes full job with 3+ checkpoints
- Integration test: Verify worker_history has N records after N checkpoints
- Integration test: Worker resumes from checkpoint after simulated crash

---

## Progress Log

### [Date] - [Status Update]
- [Notes on implementation progress]
