# A01-T055: Add multi-tier statistics retention configuration support

**Phase:** A01 - Performance & Optimization (Adhoc)  
**Status:** Not Started  
**Priority:** Medium  
**Dependencies:** A01-T050  
**Estimated Effort:** Small (< 1h)

---

## Description

Add configuration support for environment variables controlling retention limits across all four statistics tiers. This provides operators flexibility to tune storage vs. history trade-offs based on available resources and monitoring requirements.

---

## Acceptance Criteria

- [ ] Add `WorkerHistoryLimit` field to `internal/config/config.go` Config struct  
- [ ] Add `WorkerDailyStatsLimit` field (per-worker cap for daily aggregation)
- [ ] Add `WorkerMonthlyStatsLimit` field (per-worker cap for monthly aggregation)
- [ ] Read from environment variables with defaults:
  - `WORKER_HISTORY_LIMIT=10000` (global cap for raw history)
  - `WORKER_DAILY_STATS_LIMIT=1000` (per-worker cap)
  - `WORKER_MONTHLY_STATS_LIMIT=1000` (per-worker cap)
- [ ] Validate configuration: all values must be > 0, warn if < 100 (too small)
- [ ] Add configuration to `internal/database/connection.go` initialization
- [ ] Implement dynamic trigger creation based on configured limits (recreate triggers at DB init)
- [ ] Update README.md with new environment variable documentation
- [ ] Write unit test for config validation (zero value should fail or use default)
- [ ] Write integration test verifying limits are respected after configuration change

---

## Implementation Notes

**Config Structure:**
```go
type Config struct {
    Port                    string
    DBPath                  string
    WorkerHistoryLimit      int  // Global cap for raw history (Tier 1)
    WorkerDailyStatsLimit   int  // Per-worker cap for daily aggregation (Tier 2)
    WorkerMonthlyStatsLimit int  // Per-worker cap for monthly aggregation (Tier 3)
    // Note: Tier 4 (lifetime) has no cap - 1 record per worker forever
}
```

**Environment Variables:**
```bash
WORKER_HISTORY_LIMIT=10000         # Global cap (default)
WORKER_DAILY_STATS_LIMIT=1000      # Per-worker daily cap (default)
WORKER_MONTHLY_STATS_LIMIT=1000    # Per-worker monthly cap (default)
```

**Validation Logic:**
```go
// Validate and set defaults
func (cfg *Config) Validate() error {
    if cfg.WorkerHistoryLimit <= 0 {
        log.Printf("WARNING: WORKER_HISTORY_LIMIT must be > 0, using default 10000")
        cfg.WorkerHistoryLimit = 10000
    }
    if cfg.WorkerHistoryLimit < 100 {
        log.Printf("WARNING: WORKER_HISTORY_LIMIT is very low (%d), may lose recent history quickly", cfg.WorkerHistoryLimit)
    }
    
    if cfg.WorkerDailyStatsLimit <= 0 {
        log.Printf("WARNING: WORKER_DAILY_STATS_LIMIT must be > 0, using default 1000")
        cfg.WorkerDailyStatsLimit = 1000
    }
    
    if cfg.WorkerMonthlyStatsLimit <= 0 {
        log.Printf("WARNING: WORKER_MONTHLY_STATS_LIMIT must be > 0, using default 1000")
        cfg.WorkerMonthlyStatsLimit = 1000
    }
    
    return nil
}
```

**Dynamic Trigger Creation:**

The database initialization code should recreate triggers with configured limits:

```go
func createRetentionTriggers(db *sql.DB, cfg *config.Config) error {
    // Drop existing triggers (if any)
    dropTriggers := []string{
        "DROP TRIGGER IF EXISTS prune_worker_history",
        "DROP TRIGGER IF EXISTS prune_daily_stats_per_worker",
        "DROP TRIGGER IF EXISTS prune_monthly_stats_per_worker",
    }
    for _, stmt := range dropTriggers {
        if _, err := db.Exec(stmt); err != nil {
            return fmt.Errorf("drop trigger: %w", err)
        }
    }
    
    // Create worker_history pruning trigger (global limit)
    historyTrigger := fmt.Sprintf(`
    CREATE TRIGGER prune_worker_history
    AFTER INSERT ON worker_history
    WHEN (SELECT COUNT(*) FROM worker_history) > %d
    BEGIN
        DELETE FROM worker_history 
        WHERE id IN (
            SELECT id FROM worker_history 
            ORDER BY id ASC 
            LIMIT (SELECT COUNT(*) - %d FROM worker_history)
        );
    END;
    `, cfg.WorkerHistoryLimit, cfg.WorkerHistoryLimit)
    
    // Create daily stats pruning trigger (per-worker limit)
    dailyTrigger := fmt.Sprintf(`
    CREATE TRIGGER prune_daily_stats_per_worker
    AFTER INSERT ON worker_stats_daily
    FOR EACH ROW
    WHEN (SELECT COUNT(*) FROM worker_stats_daily WHERE worker_id = NEW.worker_id) > %d
    BEGIN
        DELETE FROM worker_stats_daily
        WHERE worker_id = NEW.worker_id
        AND id IN (
            SELECT id FROM worker_stats_daily
            WHERE worker_id = NEW.worker_id
            ORDER BY stats_date ASC
            LIMIT (SELECT COUNT(*) - %d FROM worker_stats_daily WHERE worker_id = NEW.worker_id)
        );
    END;
    `, cfg.WorkerDailyStatsLimit, cfg.WorkerDailyStatsLimit)
    
    // Create monthly stats pruning trigger (per-worker limit)
    monthlyTrigger := fmt.Sprintf(`
    CREATE TRIGGER prune_monthly_stats_per_worker
    AFTER INSERT ON worker_stats_monthly
    FOR EACH ROW
    WHEN (SELECT COUNT(*) FROM worker_stats_monthly WHERE worker_id = NEW.worker_id) > %d
    BEGIN
        DELETE FROM worker_stats_monthly
        WHERE worker_id = NEW.worker_id
        AND id IN (
            SELECT id FROM worker_stats_monthly
            WHERE worker_id = NEW.worker_id
            ORDER BY stats_month ASC
            LIMIT (SELECT COUNT(*) - %d FROM worker_stats_monthly WHERE worker_id = NEW.worker_id)
        );
    END;
    `, cfg.WorkerMonthlyStatsLimit, cfg.WorkerMonthlyStatsLimit)
    
    // Execute trigger creation
    triggers := []string{historyTrigger, dailyTrigger, monthlyTrigger}
    for _, trigger := range triggers {
        if _, err := db.Exec(trigger); err != nil {
            return fmt.Errorf("create trigger: %w", err)
        }
    }
    
    return nil
}
```

**Integration:**
Call `createRetentionTriggers` from `database.InitDB()` after schema application.

**Reference:**
- See `docs/architecture/db-optimization-proposal.md` section 3

---

## Testing Strategy

- Unit test: Config loads default values when env vars not set (10000, 1000, 1000)
- Unit test: Config loads custom values from all three env vars
- Unit test: Validation rejects zero/negative values and uses defaults
- Unit test: Warning logged when values are too low (< 100)
- Integration test: Set WORKER_HISTORY_LIMIT to 50, insert 100 records, verify table has exactly 50
- Integration test: Set WORKER_DAILY_STATS_LIMIT to 20, insert 30 daily records for worker A, verify exactly 20 remain
- Integration test: Set WORKER_MONTHLY_STATS_LIMIT to 15, insert 25 monthly records for worker B, verify exactly 15 remain
- Integration test: Verify other workers' stats are not affected when one worker's limit is hit
- Integration test: Change limit values and reinitialize DB, verify new limits take effect

---

## Progress Log

### [Date] - [Status Update]
- [Notes on implementation progress]
